# üöÄ SoloPilot ‚Äì End-to-End Freelance Automation Platform

[![CI Status](https://github.com/your-username/SoloPilot/workflows/CI/badge.svg)](https://github.com/your-username/SoloPilot/actions)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=solopilot_ai_automation&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=solopilot_ai_automation)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=solopilot_ai_automation&metric=coverage)](https://sonarcloud.io/summary/new_code?id=solopilot_ai_automation)
[![Code Smells](https://sonarcloud.io/api/project_badges/measure?project=solopilot_ai_automation&metric=code_smells)](https://sonarcloud.io/summary/new_code?id=solopilot_ai_automation)

**SoloPilot** automates the entire freelance development process from client email to deployed website. Our AI agents handle requirements gathering, development, review, and deployment‚Äîdelivering professional websites in days, not weeks.

## üéØ Vision

Transform freelance development by automating everything except client relationships:
- **Email arrives** ‚Üí Requirements extracted via conversational AI
- **AI builds** ‚Üí Code reviewed automatically with quality gates
- **Deploy happens** ‚Üí Client gets live site on custom domain
- **Portfolio grows** ‚Üí Case studies attract more clients

### üõ°Ô∏è Production-Ready Features
- **AI Code Review**: Every PR reviewed by AI + SonarCloud
- **Token Optimization**: Serena LSP reduces costs by 50% (822 avg tokens)
- **Quality Gates**: Automated testing on Ubuntu/macOS
- **Cost Control**: <$50/month infrastructure target

## üåü Current Status (June 2025)

### ‚úÖ Completed
- **Sprint 1**: AI provider abstraction, cost telemetry, context engines
- **Serena Integration**: Symbol-aware context with 2x token efficiency
- **AI Pair Reviewer**: Automated code review with CI integration
- **Email Intake Agent**: AWS SES-based requirement extraction

### üöß In Progress
- **First Client Demo**: End-to-end delivery of real freelance project
- **Deployment Pipeline**: GitHub ‚Üí Vercel automation

### üìÖ Coming Next
- **Client Communication**: Automated progress updates
- **Portfolio Generation**: Case studies from completed projects
- **Billing Integration**: Stripe for payments

## üèóÔ∏è Architecture

```mermaid
flowchart TD
    subgraph "Client Acquisition"
        A[Apollo.io Outreach] --> B[Email Reply]
        B --> C[AWS SES]
    end
    
    subgraph "Email Processing"
        C --> D[S3 Storage]
        D --> E[Lambda: Email Intake Agent]
        E --> F[DynamoDB: Conversation State]
        E --> G[Bedrock: Extract Requirements]
        G --> H[SES: Send Follow-ups]
        E --> I[SQS: Pipeline Handoff]
    end
    
    subgraph "Development Pipeline"
        I --> J[Analyser Agent]
        J --> K[Planning Agent]
        K --> L[Dev Agent + Serena LSP]
        L --> M[AI Reviewer]
        M --> |Pass| N[Auto Deploy]
        M --> |Fail| O[Block & Fix]
    end
    
    subgraph "Delivery"
        N --> P[Vercel/Netlify]
        P --> Q[Custom Domain]
        Q --> R[Client Notification]
        R --> S[Portfolio Case Study]
    end
```

## üìÇ Module Overview

| Module | Status | Purpose |
|--------|--------|---------|
| **email_intake** | ‚úÖ Active | Process client emails, extract requirements |
| **analyser** | ‚úÖ Active | Parse requirements into structured specs |
| **planning** | ‚úÖ Active | Convert specs into development roadmaps |
| **dev** | ‚úÖ Active | Generate code with Serena context engine |
| **review** | ‚úÖ Active | AI code review + static analysis |
| **deploy** | üöß Building | Automated deployment to hosting platforms |
| **marketing** | ‚úÖ Active | Generate announcements and case studies |
| **coordination** | üîÑ Planned | Orchestrate multi-agent workflows |

## üß© Tech Stack

### Core Infrastructure
- **Cloud**: AWS (SES, Lambda, DynamoDB, SQS, Bedrock)
- **LLM**: Claude 4 Sonnet via Bedrock (primary), GPT-4 (fallback)
- **Context**: Serena LSP for symbol-aware code understanding
- **Deployment**: Vercel/Netlify with GitHub Actions

### Development Stack
- **Backend**: Python 3.13, FastAPI
- **Frontend**: Next.js 14, TypeScript, Tailwind CSS
- **Database**: Supabase (PostgreSQL + Auth)
- **Payments**: Stripe (planned)

### Quality & Monitoring
- **CI/CD**: GitHub Actions with matrix testing
- **Code Quality**: Ruff, Black, MyPy, SonarCloud
- **Monitoring**: CloudWatch, custom telemetry
- **Cost Tracking**: Per-call LLM logging to `logs/llm_calls.log`

## üöÄ Quick Start

### Prerequisites
```bash
# AWS CLI configured with credentials
aws configure

# Python 3.11+ and Node.js 18+
python --version
node --version
```

### Local Development
```bash
# Clone and setup
git clone <repo-url>
cd SoloPilot

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the full pipeline
make plan-dev

# With Serena context engine
CONTEXT_ENGINE=serena make dev
```

### Email Intake Setup
```bash
# 1. Configure AWS SES domain
# 2. Create S3 bucket for emails
# 3. Deploy Lambda function
cd agents/email_intake
zip -r email-intake.zip .
# Upload to Lambda

# 4. Set environment variables
REQUIREMENT_QUEUE_URL=<your-sqs-queue>
SENDER_EMAIL=<your-verified-email>
DYNAMO_TABLE=conversations
```

## ‚öôÔ∏è Configuration

### Environment Variables

**AI Provider Settings:**
- `AI_PROVIDER`: bedrock (default) | fake | openai
- `BEDROCK_IP_ARN`: Claude 4 Sonnet inference profile
- `NO_NETWORK`: Force offline mode for testing

**Context Engine Settings:**
- `CONTEXT_ENGINE`: serena (recommended) | legacy | lc_chroma
- `SERENA_BALANCED_TARGET`: Token budget (default: 1500)
- `SERENA_TELEMETRY_ENABLED`: Production monitoring

**Deployment Settings:**
- `VERCEL_TOKEN`: For automated deployments
- `GITHUB_TOKEN`: For PR reviews
- `SONAR_TOKEN`: For code quality analysis

## üìã Development Workflow

### Standard Commands
```bash
# Activate environment
source .venv/bin/activate

# Run tests
make test

# Lint and format
make lint

# Full pipeline test
make plan-dev

# Deploy to production
make deploy
```

### AI Review Workflow
```bash
# Review current code
make review

# If review passes, promote to staging
make promote

# Generate marketing announcement
make announce
```

## üîç Quality Assurance

### Automated Checks
1. **AI Code Review**: Every PR reviewed for bugs, security, performance
2. **Static Analysis**: Ruff, MyPy, Black formatting
3. **SonarCloud**: Security vulnerabilities and code smells
4. **Token Validation**: CI enforces <2000 tokens per call

### Manual Verification
- Review `logs/llm_calls.log` for cost monitoring
- Check `serena_telemetry.jsonl` for performance metrics
- Verify deployment smoke tests pass

## üìà Metrics & Monitoring

### Key Performance Indicators
- **Token Usage**: 822 avg per context (target: <1500)
- **Response Time**: <3s for email processing
- **Pipeline Duration**: <10 mins from email to deployed site
- **Cost per Project**: <$5 in LLM calls

### Telemetry
When `SERENA_TELEMETRY_ENABLED=1`:
- Token usage per request
- Symbol lookup performance
- Budget violations
- Response times

## üéØ Roadmap

### Phase 1: MVP (Current)
- ‚úÖ Core agent pipeline
- ‚úÖ Email intake system
- üöß Deployment automation
- üöß First client demo

### Phase 2: Scale (July 2025)
- Multi-channel intake (SMS, chat)
- Payment automation
- Client portal
- Advanced project types

### Phase 3: Growth (August 2025)
- Team collaboration features
- White-label options
- API for integrations
- Global deployment regions

## üìù License

Proprietary - SoloPilot AI Automation