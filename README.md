# ğŸš€ SoloPilot â€“ End-to-End Freelance Automation Platform

[![CI Status](https://github.com/your-username/SoloPilot/workflows/CI/badge.svg)](https://github.com/your-username/SoloPilot/actions)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=solopilot_ai_automation&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=solopilot_ai_automation)
[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=solopilot_ai_automation&metric=coverage)](https://sonarcloud.io/summary/new_code?id=solopilot_ai_automation)
[![Code Smells](https://sonarcloud.io/api/project_badges/measure?project=solopilot_ai_automation&metric=code_smells)](https://sonarcloud.io/summary/new_code?id=solopilot_ai_automation)

**SoloPilot** automates the entire freelance development process from client email to deployed website. Our AI agents handle requirements gathering, development, review, and deploymentâ€”delivering professional websites in days, not weeks.

## ğŸ¯ Vision

Transform freelance development by automating everything except client relationships:
- **Email arrives** â†’ Requirements extracted via conversational AI
- **AI builds** â†’ Code reviewed automatically with quality gates
- **Deploy happens** â†’ Client gets live site on custom domain
- **Portfolio grows** â†’ Case studies attract more clients

### ğŸ›¡ï¸ Production-Ready Features
- **AI Code Review**: Every PR reviewed by AI + SonarCloud
- **Token Optimization**: Serena LSP reduces costs by 50% (822 avg tokens)
- **Quality Gates**: Automated testing on Ubuntu/macOS
- **Cost Control**: <$50/month infrastructure target

## ğŸŒŸ Current Status (June 2025)

### âœ… Completed
- **Sprint 1**: AI provider abstraction, cost telemetry, context engines
- **Serena Integration**: Symbol-aware context with 2x token efficiency
- **AI Pair Reviewer**: Automated code review with CI integration
- **Email Intake Agent**: AWS SES-based requirement extraction

### ğŸš§ In Progress
- **First Client Demo**: End-to-end delivery of real freelance project
- **Deployment Pipeline**: GitHub â†’ Vercel automation

### ğŸ“… Coming Next
- **Client Communication**: Automated progress updates
- **Portfolio Generation**: Case studies from completed projects
- **Billing Integration**: Stripe for payments

## ğŸ—ï¸ Architecture

```mermaid
flowchart TD
    subgraph "Client Acquisition"
        A[Apollo.io Outreach] --> B[Email Reply]
        B --> C[AWS SES]
    end

    subgraph "Email Processing"
        C --> D[S3 Storage]
        D --> E[Lambda: Email Intake Agent]
        E --> F[DynamoDB: Conversation State]
        E --> G[Bedrock: Extract Requirements]
        G --> H[SES: Send Follow-ups]
        E --> I[SQS: Pipeline Handoff]
    end

    subgraph "Development Pipeline"
        I --> J[Analyser Agent]
        J --> K[Planning Agent]
        K --> L[Dev Agent + Serena LSP]
        L --> M[AI Reviewer]
        M --> |Pass| N[Auto Deploy]
        M --> |Fail| O[Block & Fix]
    end

    subgraph "Delivery"
        N --> P[Vercel/Netlify]
        P --> Q[Custom Domain]
        Q --> R[Client Notification]
        R --> S[Portfolio Case Study]
    end
```

## ğŸ“‚ Project Structure

```
SoloPilot/
â”œâ”€â”€ src/                          # All source code
â”‚   â”œâ”€â”€ agents/                   # Agent implementations
â”‚   â”‚   â”œâ”€â”€ analyser/            # Requirements analysis
â”‚   â”‚   â”œâ”€â”€ dev/                 # Code generation with context engines
â”‚   â”‚   â”œâ”€â”€ email_intake/        # Email processing & client communication
â”‚   â”‚   â”œâ”€â”€ marketing/           # Portfolio & case study generation
â”‚   â”‚   â”œâ”€â”€ planning/            # Project planning & milestones
â”‚   â”‚   â””â”€â”€ review/              # AI code review & quality gates
â”‚   â”œâ”€â”€ providers/               # AI provider implementations
â”‚   â”‚   â”œâ”€â”€ base.py             # Abstract base provider
â”‚   â”‚   â”œâ”€â”€ bedrock.py          # AWS Bedrock (Claude)
â”‚   â”‚   â”œâ”€â”€ openai.py           # OpenAI GPT-4
â”‚   â”‚   â””â”€â”€ fake.py             # Testing provider
â”‚   â”œâ”€â”€ common/                  # Shared utilities
â”‚   â”‚   â””â”€â”€ bedrock_client.py   # Centralized Bedrock client
â”‚   â””â”€â”€ utils/                   # General utilities
â”‚       â”œâ”€â”€ github_review.py     # GitHub PR integration
â”‚       â”œâ”€â”€ linter_integration.py # Code quality tools
â”‚       â””â”€â”€ sonarcloud_integration.py # SonarCloud analysis
â”œâ”€â”€ frontend/                    # Frontend applications
â”‚   â””â”€â”€ email-intake/           # Email intake dashboard (React)
â”œâ”€â”€ infrastructure/             # Deployment & IaC
â”‚   â”œâ”€â”€ terraform/             # Infrastructure as Code
â”‚   â””â”€â”€ lambda/                # Lambda functions
â”œâ”€â”€ tests/                     # All test files
â”œâ”€â”€ examples/                  # Example inputs & demos
â”œâ”€â”€ scripts/                   # Development & CI scripts
â”œâ”€â”€ docs/                      # Documentation
â””â”€â”€ pyproject.toml            # Poetry dependency management
```

## ğŸ“‹ Module Overview

| Module | Status | Purpose |
|--------|--------|---------|
| **email_intake** | âœ… Active | Process client emails, extract requirements |
| **analyser** | âœ… Active | Parse requirements into structured specs |
| **planning** | âœ… Active | Convert specs into development roadmaps |
| **dev** | âœ… Active | Generate code with Serena context engine |
| **review** | âœ… Active | AI code review + static analysis |
| **deploy** | ğŸš§ Building | Automated deployment to hosting platforms |
| **marketing** | âœ… Active | Generate announcements and case studies |
| **coordination** | ğŸ”„ Planned | Orchestrate multi-agent workflows |

## ğŸ§© Tech Stack

### Core Infrastructure
- **Cloud**: AWS (SES, Lambda, DynamoDB, SQS, Bedrock)
- **LLM**: Claude 4 Sonnet via Bedrock (primary), GPT-4 (fallback)
- **Context**: Serena LSP for symbol-aware code understanding
- **Deployment**: Vercel/Netlify with GitHub Actions

### Development Stack
- **Backend**: Python 3.9+, FastAPI, Poetry
- **Frontend**: Next.js 14, TypeScript, Tailwind CSS
- **Database**: Supabase (PostgreSQL + Auth)
- **Payments**: Stripe (planned)

### Quality & Monitoring
- **CI/CD**: GitHub Actions with matrix testing (Python 3.9-3.12)
- **Code Quality**: Pre-commit hooks, Black, isort, Ruff, MyPy, Bandit
- **Static Analysis**: SonarCloud integration
- **Monitoring**: CloudWatch, custom telemetry
- **Cost Tracking**: Per-call LLM logging to `logs/llm_calls.log`

## ğŸš€ Quick Start

### Prerequisites
```bash
# AWS CLI configured with credentials
aws configure

# Python 3.9+ and Node.js 18+
python --version  # 3.9 or higher
node --version    # 18 or higher

# Install Poetry (dependency management)
curl -sSL https://install.python-poetry.org | python3 -
```

### Local Development
```bash
# Clone and setup
git clone <repo-url>
cd SoloPilot

# Install dependencies with Poetry
poetry install

# Install pre-commit hooks
poetry run pre-commit install

# Run the full pipeline
poetry run make plan-dev

# With Serena context engine
CONTEXT_ENGINE=serena poetry run make dev

# Run tests
poetry run pytest

# Run linting and formatting
poetry run pre-commit run --all-files
```

### Email Intake Setup
```bash
# 1. Configure AWS SES domain
# 2. Create S3 bucket for emails
# 3. Deploy Lambda function
cd agents/email_intake
zip -r email-intake.zip .
# Upload to Lambda

# 4. Set environment variables
REQUIREMENT_QUEUE_URL=<your-sqs-queue>
SENDER_EMAIL=<your-verified-email>
DYNAMO_TABLE=conversations
```

## âš™ï¸ Configuration

### Environment Variables

**AI Provider Settings:**
- `AI_PROVIDER`: bedrock (default) | fake | openai
- `BEDROCK_IP_ARN`: Claude 4 Sonnet inference profile
- `NO_NETWORK`: Force offline mode for testing

**Context Engine Settings:**
- `CONTEXT_ENGINE`: serena (recommended) | legacy | lc_chroma
- `SERENA_BALANCED_TARGET`: Token budget (default: 1500)
- `SERENA_TELEMETRY_ENABLED`: Production monitoring

**Deployment Settings:**
- `VERCEL_TOKEN`: For automated deployments
- `GITHUB_TOKEN`: For PR reviews
- `SONAR_TOKEN`: For code quality analysis

## ğŸ“‹ Development Workflow

### Standard Commands
```bash
# Activate environment
source .venv/bin/activate

# Run tests
make test

# Lint and format
make lint

# Full pipeline test
make plan-dev

# Deploy to production
make deploy
```

### AI Review Workflow
```bash
# Review current code
make review

# If review passes, promote to staging
make promote

# Generate marketing announcement
make announce
```

## ğŸ” Quality Assurance

### Automated Checks
1. **AI Code Review**: Every PR reviewed for bugs, security, performance
2. **Static Analysis**: Ruff, MyPy, Black formatting
3. **SonarCloud**: Security vulnerabilities and code smells
4. **Token Validation**: CI enforces <2000 tokens per call

### Manual Verification
- Review `logs/llm_calls.log` for cost monitoring
- Check `serena_telemetry.jsonl` for performance metrics
- Verify deployment smoke tests pass

## ğŸ“ˆ Metrics & Monitoring

### Key Performance Indicators
- **Token Usage**: 822 avg per context (target: <1500)
- **Response Time**: <3s for email processing
- **Pipeline Duration**: <10 mins from email to deployed site
- **Cost per Project**: <$5 in LLM calls

### Telemetry
When `SERENA_TELEMETRY_ENABLED=1`:
- Token usage per request
- Symbol lookup performance
- Budget violations
- Response times

## ğŸ¯ Roadmap

### Phase 1: MVP (Current)
- âœ… Core agent pipeline
- âœ… Email intake system
- ğŸš§ Deployment automation
- ğŸš§ First client demo

### Phase 2: Scale (July 2025)
- Multi-channel intake (SMS, chat)
- Payment automation
- Client portal
- Advanced project types

### Phase 3: Growth (August 2025)
- Team collaboration features
- White-label options
- API for integrations
- Global deployment regions

## ğŸ“ License

Proprietary - SoloPilot AI Automation
