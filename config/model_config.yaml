# SoloPilot Model Configuration
# Configuration for LLM endpoints and processing parameters

# LLM Configuration
llm:
  # Primary LLM (AWS Bedrock)
  primary: "bedrock"
  
  # Fallback LLM (OpenAI)
  fallback: "openai"
  
  # AWS Bedrock Configuration
  bedrock:
    model_id: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    region: "us-east-2"
    timeout: 60  # seconds
    model_kwargs:
      temperature: 0.1
      top_p: 0.9
      max_tokens: 2048
    # Alternative models (comment/uncomment as needed):
    # model_id: "anthropic.claude-3-5-haiku-20241022-v1:0"   # Newer Haiku (requires inference profile)
    # model_id: "meta.llama3-1-8b-instruct-v1:0"            # Llama 3.1 8B (cheaper)
    # model_id: "anthropic.claude-3-5-sonnet-20241022-v2:0"  # Claude 3.5 Sonnet (more capable)
  
  # OpenAI Configuration (fallback)
  openai:
    model: "gpt-4o-mini"
    api_base: "https://api.openai.com/v1"
    timeout: 60
    max_tokens: 2048
    temperature: 0.1
    top_p: 0.9

# Processing Configuration
processing:
  # Text processing
  text:
    max_file_size_mb: 10
    chunk_size: 4000  # characters per chunk for large files
    overlap: 200     # character overlap between chunks
  
  # Image processing
  image:
    max_file_size_mb: 50
    max_dimension: 2048  # resize images larger than this
    ocr_config: "--oem 3 --psm 6"  # tesseract configuration
    supported_formats:
      - "png"
      - "jpg" 
      - "jpeg"
      - "gif"
      - "bmp"
      - "tiff"
  
  # Archive processing
  archive:
    max_extract_size_mb: 100
    max_files: 50

# Output Configuration
output:
  # Directory structure
  base_dir: "analysis/output"
  create_timestamp_dirs: true
  
  # Artifact generation
  artifacts:
    generate_diagrams: true
    generate_wireframes: true
    diagram_format: "mermaid"
    
  # Export formats
  export:
    json: true
    yaml: true
    markdown: true

# Prompt Templates
prompts:
  # Requirement extraction prompt
  extraction: |
    Analyze the following client requirement text and extract structured information.
    Return a JSON object with these exact keys:
    
    {
      "title": "Brief project title",
      "summary": "2-3 sentence project summary", 
      "features": [
        {"name": "Feature name", "desc": "Feature description"}
      ],
      "constraints": ["List of technical or business constraints"],
      "tech_stack": ["Mentioned technologies or preferences"],
      "timeline": "Estimated timeline if mentioned",
      "budget": "Budget constraints if mentioned"
    }
    
    Client Requirements:
    {text}
    
    Respond with ONLY the JSON object, no additional text:
  
  # Feature enhancement prompt
  enhancement: |
    Based on the extracted requirements, suggest 2-3 additional features 
    that would enhance the project but weren't explicitly mentioned:
    
    Requirements: {requirements}
    
    Return as JSON array:
    [{"name": "Feature", "desc": "Description", "priority": "low|medium|high"}]

# Performance Configuration
performance:
  # Caching
  cache_llm_responses: true
  cache_duration_hours: 24
  
  # Parallel processing
  max_concurrent_files: 3
  max_concurrent_images: 2
  
  # Memory management
  max_memory_mb: 1024

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/solopilot.log"
  max_file_size_mb: 10
  backup_count: 5