name: CI

on:
  push:
    branches: [ main, feature/*, chore/* ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: true
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ['3.13']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache virtual environment
      uses: actions/cache@v4
      with:
        path: .venv
        key: ${{ runner.os }}-python-${{ matrix.python-version }}-venv-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-python-${{ matrix.python-version }}-venv-

    - name: Install system dependencies (macOS)
      if: matrix.os == 'macos-latest'
      run: |
        brew install tesseract

    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y tesseract-ocr

    - name: Set up virtual environment and install dependencies
      run: |
        make venv

    - name: Run tests
      env:
        AWS_ACCESS_KEY_ID: dummy
        AWS_SECRET_ACCESS_KEY: dummy
        BEDROCK_IP_ARN: arn:aws:bedrock:us-east-2:111111111111:inference-profile/dummy
        NO_NETWORK: 1
        AI_PROVIDER: fake
      run: |
        source .venv/bin/activate
        pytest -q

    - name: Run linting and formatting checks
      run: |
        source .venv/bin/activate
        pip install ruff black isort
        echo "Running ruff checks..."
        ruff check . || echo "Ruff checks completed with warnings"
        echo "Running black formatting check..."
        black --check . || echo "Black formatting check completed"
        echo "Running isort check..."
        isort --check-only . --profile=black || echo "isort check completed"

    - name: Run performance benchmarks
      env:
        AI_PROVIDER: fake
        NO_NETWORK: 1
      run: |
        poetry run python tests/performance/benchmark_suite.py || echo "Performance benchmarks completed"

  type-check:
    name: Type Checking
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: 1.7.1
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: .venv
        key: ubuntu-latest-python-3.12-poetry-${{ hashFiles('poetry.lock') }}
        restore-keys: |
          ubuntu-latest-python-3.12-poetry-

    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-ansi

    - name: Run mypy type checking
      run: |
        poetry run mypy src/ --config-file pyproject.toml

    - name: Upload mypy results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: mypy-results
        path: |
          .mypy_cache/
        retention-days: 3

  integration-test:
    runs-on: ubuntu-latest
    needs: [test, type-check]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/feature/'))

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Cache virtual environment
      uses: actions/cache@v4
      with:
        path: .venv
        key: ubuntu-latest-python-3.13-venv-${{ hashFiles('requirements.txt') }}

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y tesseract-ocr

    - name: Set up virtual environment
      run: |
        make venv

    - name: Configure AWS credentials
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
      run: |
        if [ -n "$AWS_ACCESS_KEY_ID" ]; then
          echo "AWS credentials configured"
        else
          echo "AWS credentials not available - integration tests will use fallbacks"
        fi

    - name: Test Bedrock connectivity
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
      timeout-minutes: 5
      run: |
        echo "Testing direct Bedrock connectivity..."
        if [ -n "$AWS_ACCESS_KEY_ID" ]; then
          poetry run pytest scripts/test_bedrock_direct.py -v --tb=short || echo "Bedrock connectivity test failed - may be due to credentials or permissions"
        else
          echo "Skipping Bedrock test - no AWS credentials configured"
        fi

    - name: Run complex project validation (offline)
      env:
        AI_PROVIDER: fake
        NO_NETWORK: 1
      timeout-minutes: 15
      run: |
        echo "Running complex project validation with fake provider..."
        poetry run python scripts/validate_complex_projects.py || echo "Complex project validation completed (offline mode)"

    - name: Run integration test (full pipeline with real LLM)
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
      timeout-minutes: 20
      run: |
        echo "Running full pipeline integration test..."
        if [ -n "$AWS_ACCESS_KEY_ID" ]; then
          poetry run pytest tests/test_integration_pipeline.py::TestIntegrationPipeline::test_full_pipeline_integration -v --tb=short || echo "Full pipeline test failed - may be due to credentials or LLM limits"
        else
          echo "Running fallback integration test without real LLM calls..."
          AI_PROVIDER=fake poetry run python scripts/run_planner.py sample_input/email_proposal.json && poetry run python scripts/run_dev_agent.py analysis/planning/selected_milestone_plan.json || echo "Integration test completed with fallbacks"
        fi

    - name: Upload test artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-outputs
        path: |
          analysis/output/
          analysis/planning/
          output/dev/
          logs/
        retention-days: 7

  sonarcloud:
    name: SonarCloud Analysis
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better analysis

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Poetry and dependencies
      uses: snok/install-poetry@v1
      with:
        version: 1.7.1
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-ansi

    - name: Run tests with coverage
      env:
        NO_NETWORK: 1
        AI_PROVIDER: fake
      run: |
        poetry run pytest --cov=src --cov-report=xml --cov-report=term-missing

    - name: SonarCloud Scan
      uses: SonarSource/sonarcloud-github-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  code-review:
    name: AI Code Review
    runs-on: ubuntu-latest
    needs: [test, type-check, sonarcloud]
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Poetry and dependencies
      uses: snok/install-poetry@v1
      with:
        version: 1.7.1
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-ansi

    - name: Run AI Code Review
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        AI_PROVIDER: fake  # Use fake provider in CI for consistency
        NO_NETWORK: 1
      run: |
        # Create a temporary milestone directory for review
        mkdir -p temp_review/milestone-test
        cp -r src/ temp_review/milestone-test/

        # Run reviewer agent
        poetry run python -m src.agents.review.reviewer_agent temp_review/milestone-test

        # Post review to PR if GitHub token is available
        if [ -n "$GITHUB_TOKEN" ] && [ "$NO_NETWORK" != "1" ]; then
          poetry run python scripts/post_review_to_pr.py temp_review/milestone-test/review-report.md
        else
          echo "Skipping GitHub review posting (offline mode or no token)"
          cat temp_review/milestone-test/review-report.md
        fi

  promote:
    name: Promote to Staging
    runs-on: ubuntu-latest
    needs: [integration-test, type-check, sonarcloud, code-review]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for merge

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install Poetry and dependencies
      uses: snok/install-poetry@v1
      with:
        version: 1.7.1
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-ansi

    - name: Run AI Code Review for Promotion
      env:
        AI_PROVIDER: fake  # Use fake provider for CI consistency
        NO_NETWORK: 1
      run: |
        # Create milestone directory with latest code
        mkdir -p promotion_review/milestone-main
        cp -r src/ promotion_review/milestone-main/
        cp -r scripts/ promotion_review/milestone-main/ || true

        # Run review
        poetry run python -m src.agents.review.reviewer_agent promotion_review/milestone-main

        # Check review status
        echo "REVIEW_STATUS=$(poetry run python scripts/check_review_status.py promotion_review/milestone-main/review-report.md)" >> $GITHUB_ENV

    - name: Fast-forward merge to staging
      if: env.REVIEW_STATUS == 'pass'
      run: |
        git config user.name "GitHub Actions Bot"
        git config user.email "actions@github.com"

        # Check if staging branch exists
        if git show-ref --verify --quiet refs/remotes/origin/staging; then
          echo "Staging branch exists, checking out..."
          git checkout staging
          git merge --ff-only main
        else
          echo "Creating new staging branch..."
          git checkout -b staging
        fi

        # Push to staging (skip in forks or if no push access)
        if [ "$GITHUB_REPOSITORY" != "your-username/SoloPilot" ] || [ "${{ github.event.repository.fork }}" = "true" ]; then
          echo "Skipping push to staging (fork or insufficient permissions)"
        else
          git push origin staging || echo "Failed to push to staging - may be due to permissions"
        fi

    - name: Create promotion summary
      if: always()
      run: |
        echo "## 🚀 Promotion Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Review Status**: ${{ env.REVIEW_STATUS || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
        echo "**Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        if [ "${{ env.REVIEW_STATUS }}" = "pass" ]; then
          echo "✅ **Result**: Code promoted to staging branch" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Result**: Promotion blocked due to review failures" >> $GITHUB_STEP_SUMMARY
        fi
